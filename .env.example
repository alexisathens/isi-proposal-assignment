# Ollama Configuration
# URL of your Ollama server (change to your actual server address)
OLLAMA_HOST=http://localhost:11434

# Embedding model to use (must be available in Ollama)
# Common options: nomic-embed-text, mxbai-embed-large
IPS_EMBED_MODEL=nomic-embed-text

# Sleep time between API calls (in seconds) to avoid overloading the server
IPS_EMBED_SLEEP_SEC=0.5
